{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Experiments\n",
    "\n",
    "This notebook implements the three pricing policies (static pricing, iterative pricing, and match-based pricing) on the Chicago dataset assuming a cost $c=0.9$, an average sojourn time of 3 min, a sharing disutility factor $\\beta_0=0.05$, and a detour disutility factor $\\beta_0=0.675$. Each policy is trained and evaluated on both training and test datasets. Detailed experimental methodology can be found in Section 4 of the paper, and the complete evaluation results are presented in Table 2 in Section 4 and Table EC.2 in Appendix EC.3.3.\n",
    "\n",
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external packages\n",
    "import numpy as np\n",
    "import copy\n",
    "from gurobipy import *\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# internal packages\n",
    "from lib.network import osm\n",
    "from lib.instance_data import InstanceData\n",
    "from lib.utils import (\n",
    "    import_demand,\n",
    "    TRAINING_SET_KEY,  # training dataset key\n",
    "    TEST_SET_KEY,  # test dataset key\n",
    "    MATCH_KEY,  # match-based pricing policy key\n",
    "    STATIC_KEY,  # static pricing policy key\n",
    "    ITERATIVE_KEY,  # iterative pricing policy key\n",
    "    SYN_DATA_KEY,  # synthetic data key\n",
    "    REAL_DATA_KEY,  # real data key\n",
    ")\n",
    "from lib.policies import (\n",
    "    MatchPricingAffineMatchingCombined,\n",
    "    StaticPricingAffineMatchingCombined,\n",
    "    IterativePricingAffineMatchingCombined,\n",
    "    StaticPricingPolicy,\n",
    "    MatchBasedPricingPolicy,\n",
    "    AffineMatchingPolicy,\n",
    ")\n",
    "from lib.simulation import Simulator\n",
    "from lib.evaluator import evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Chicago network data, and calculate the shortest times between nodes\n",
    "with open(\"data/Chicago_network.pickle\", \"rb\") as f:\n",
    "    network_data = pickle.load(f)\n",
    "network = osm(network_data[\"G\"], network_data[\"edge_keys\"])\n",
    "network.calculate_shortest_times()\n",
    "\n",
    "# import the demand data\n",
    "rider_types, arrival_rates, arrival_types, arrival_times = import_demand(\n",
    "    \"data/Chicago_demand.pickle\"\n",
    ")\n",
    "n_rider_types = len(rider_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for the experiments, including the paramters for policy optimization, simulation, and evaluation. For each policy, two optimization parameter sets are established: one with $\\beta_0=0, \\beta_1=0$, and another with $\\beta_0=0.05, \\beta_1=0.675$; the optimized affine weights of static and match-based pricing under the former setting will be used as a warmup for the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.9  # cost from 0 to 2 (in dollars per mile)\n",
    "sojourn_time = 180  # average sojourn time (in seconds)\n",
    "\n",
    "# ------------- Optimization parameters ------------\n",
    "# Define common parameters\n",
    "BASE_CONFIG = {\n",
    "    STATIC_KEY: {\n",
    "        \"eps_fluid\": 1e-8,  # termination criterion for optimizing the fluid model\n",
    "        \"bootstrap_rounds\": 2,  # number of bootstrap rounds for states sampling\n",
    "        \"alpha_bound\": 1,  # bounding alpha values by c*solo_length (solo dispatching cost)\n",
    "        \"shrinkage_factor\": 1,  # shrinkage factor for updating the disutility\n",
    "        \"momentum\": 0.8,  # how much to weigh the new disutility when updating the disutility\n",
    "    },\n",
    "    ITERATIVE_KEY: {\n",
    "        \"bootstrap_rounds\": 1,\n",
    "        \"alpha_bound\": 1,\n",
    "        \"shrinkage_factor\": 1,\n",
    "        \"momentum\": 0.1,\n",
    "        \"iter_max_iter\": 10,  # maximum number of iterations for iterative pricing policy\n",
    "    },\n",
    "    MATCH_KEY: {\n",
    "        \"bootstrap_rounds\": 2,\n",
    "        \"alpha_bound\": 1,\n",
    "        \"momentum\": 0.8,\n",
    "        \"shrinkage_factor\": 1,\n",
    "        \"epsilon_cutting_plane\": 0.5,  # termination criterion for cutting plane\n",
    "        \"early_stop\": True,  # stop cutting plane optimization when the objective value is not improved\n",
    "    },\n",
    "}\n",
    "# maximum detour rate\n",
    "MAX_DETOUR_RATE = 0.25\n",
    "\n",
    "opt_params = dict()\n",
    "# parameters when beta0=0, beta1=0\n",
    "# policies have no warmup affine weights as the first policy for states sampling\n",
    "opt_params[0, 0] = {\n",
    "    STATIC_KEY: {\n",
    "        **BASE_CONFIG[STATIC_KEY],\n",
    "        **{\n",
    "            \"warmup\": 0,\n",
    "            \"warmup_weights\": None,\n",
    "            \"update_disutil_opt\": False,  # whether to update the disutility in the optimization\n",
    "            \"update_disutil_eval\": False,  # whether to update the disutility in the evaluation\n",
    "        },\n",
    "    },\n",
    "    MATCH_KEY: {\n",
    "        **BASE_CONFIG[MATCH_KEY],\n",
    "        **{\n",
    "            \"warmup\": 0,\n",
    "            \"warmup_weights\": None,\n",
    "            \"update_disutil_opt\": False,\n",
    "            \"update_disutil_eval\": False,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# parameters when beta0=0.05, beta1=0.675\n",
    "# static and match-based policies use the affine weights in the results of beta0=beta1=0 as the warmup policy for states sampling\n",
    "opt_params[0.05, 0.675] = {\n",
    "    STATIC_KEY: {\n",
    "        **BASE_CONFIG[STATIC_KEY],\n",
    "        **{\n",
    "            \"warmup\": 1,\n",
    "            \"update_disutil_opt\": True,\n",
    "            \"update_disutil_eval\": True,\n",
    "        },\n",
    "    },\n",
    "    MATCH_KEY: {\n",
    "        **BASE_CONFIG[MATCH_KEY],\n",
    "        **{\"warmup\": 1, \"update_disutil_opt\": True, \"update_disutil_eval\": True},\n",
    "    },\n",
    "    ITERATIVE_KEY: {\n",
    "        **BASE_CONFIG[ITERATIVE_KEY],\n",
    "        **{\"update_disutil_opt\": True, \"update_disutil_eval\": True},\n",
    "    },\n",
    "}\n",
    "\n",
    "# ------------- Simulation parameters ------------\n",
    "sim_params = {\n",
    "    # week numbers for training/validation/test data sets\n",
    "    \"data_sets_division\": {\n",
    "        REAL_DATA_KEY: [7, 0, 1],  # real data\n",
    "        SYN_DATA_KEY: [1, 0, 0],  # synthetic data\n",
    "    },\n",
    "    # simulation time limits for training and test data sets\n",
    "    \"time_limits\": {\n",
    "        TRAINING_SET_KEY: 100000,\n",
    "        TEST_SET_KEY: 3600,\n",
    "    },\n",
    "    # simulation time for greedy matching policy\n",
    "    \"time_limit_greedy\": 40000,\n",
    "    # the observing rate for constraint sampling, which is a portion rate of the summation of total arrival rates and reneging rates\n",
    "    \"observer_rate_portion\": 0.1,\n",
    "    # a sufficiently long time for evaluating the synthetic training set during optimization\n",
    "    \"evaluation_time\": 1000000,\n",
    "}\n",
    "\n",
    "# ------------- Evaluation parameters ------------\n",
    "# maximum number of iterations (of updating the disutility) for evaluation\n",
    "EVAL_MAX_ITER = 10\n",
    "# evaluation time for synthetic training set\n",
    "training_synthetic_eval_time = 2000000\n",
    "# number of repetitions for test set evaluation\n",
    "n_repeats = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Policy training\n",
    "\n",
    "Train the static, iterative, and match-based pricing policies using a synthetic training dataset generated based on arrival rates estimated from the actual training data. The synthetic dataset is extended to be sufficiently long to ensure accurate estimation of disutilities and performance metrics, as well as diversifying the sampled states. We first train the policies for $\\beta_0=\\beta_1=0$; the affine weights from the static and match-based pricing policies are used as the warmup weights for subsequent training of the static and match-based pricing policies with $\\beta_0=0.05, \\beta_1=0.675$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= beta0=0, beta1=0 =========\n",
      "Static pricing policy was trained in 757.36 seconds.\n",
      "Match-based pricing policy was trained in 11678.66 seconds.\n",
      "========= beta0=0.05, beta1=0.675 =========\n",
      "Static pricing policy was trained in 2221.87 seconds.\n",
      "Iterative pricing policy was trained in 8099.88 seconds.\n",
      "Match-based pricing policy was trained in 4763.62 seconds.\n"
     ]
    }
   ],
   "source": [
    "# static pricing\n",
    "static_prices = dict()\n",
    "static_weights = dict()\n",
    "static_disutilities = dict()\n",
    "fluid_profits = dict()\n",
    "# iterative pricing\n",
    "iterative_prices = dict()\n",
    "iterative_weights = dict()\n",
    "iterative_disutilities = dict()\n",
    "# match-based pricing\n",
    "match_weights = dict()\n",
    "match_active_disutilities = dict()\n",
    "match_passive_disutilities = dict()\n",
    "# training time\n",
    "training_time = defaultdict(defaultdict)\n",
    "\n",
    "# train the pricing policies\n",
    "for beta0, beta1 in opt_params.keys():\n",
    "\n",
    "    # ================== train the static pricing policy ==================\n",
    "    SPAMC = StaticPricingAffineMatchingCombined()\n",
    "    (\n",
    "        fluid_static_prices,\n",
    "        fluid_disutility,\n",
    "        fluid_active_disutility,\n",
    "        fluid_passive_disutility,\n",
    "        fluid_profit,\n",
    "        opt_static_weights,\n",
    "        opt_disutility,\n",
    "        static_time,\n",
    "    ) = SPAMC.train_static_pricing_policy(\n",
    "        c,\n",
    "        sojourn_time,\n",
    "        network,\n",
    "        rider_types,\n",
    "        arrival_rates,\n",
    "        arrival_types,\n",
    "        arrival_times,\n",
    "        beta0,\n",
    "        beta1,\n",
    "        MAX_DETOUR_RATE,\n",
    "        opt_params[beta0, beta1][STATIC_KEY],\n",
    "        sim_params,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # save the optimal static prices and weights\n",
    "    static_prices[beta0, beta1] = fluid_static_prices\n",
    "    static_weights[beta0, beta1] = opt_static_weights\n",
    "    static_disutilities[beta0, beta1] = opt_disutility\n",
    "    fluid_profits[beta0, beta1] = fluid_profit\n",
    "    training_time[beta0, beta1][STATIC_KEY] = static_time\n",
    "    print(f\"========= beta0={beta0}, beta1={beta1} =========\")\n",
    "    print(f\"Static pricing policy was trained in {static_time:.2f} seconds.\")\n",
    "\n",
    "    # ================== train the iterative pricing policy ==================\n",
    "    if beta0 > 0 or beta1 > 0:\n",
    "        IPAMC = IterativePricingAffineMatchingCombined()\n",
    "        (\n",
    "            opt_iterative_price,\n",
    "            opt_iterative_weights,\n",
    "            iterative_opt_disutility,\n",
    "            iterative_time,\n",
    "        ) = IPAMC.train_iterative_pricing_policy(\n",
    "            c,\n",
    "            sojourn_time,\n",
    "            network,\n",
    "            rider_types,\n",
    "            arrival_rates,\n",
    "            arrival_types,\n",
    "            arrival_times,\n",
    "            beta0,\n",
    "            beta1,\n",
    "            MAX_DETOUR_RATE,\n",
    "            opt_params[beta0, beta1][ITERATIVE_KEY],\n",
    "            sim_params,\n",
    "            verbose=False,\n",
    "        )\n",
    "        # save the optimal iterative price and weights\n",
    "        iterative_prices[beta0, beta1] = opt_iterative_price\n",
    "        iterative_weights[beta0, beta1] = opt_iterative_weights\n",
    "        iterative_disutilities[beta0, beta1] = iterative_opt_disutility\n",
    "        training_time[beta0, beta1][ITERATIVE_KEY] = iterative_time\n",
    "        print(f\"Iterative pricing policy was trained in {iterative_time:.2f} seconds.\")\n",
    "\n",
    "    # ================== train the match-based pricing policy ==================\n",
    "    MPAMC = MatchPricingAffineMatchingCombined()\n",
    "    (\n",
    "        match_affine_weights,\n",
    "        match_active_disutility,\n",
    "        match_passive_disutility,\n",
    "        match_time,\n",
    "    ) = MPAMC.train_matchbased_pricing_policy(\n",
    "        c,\n",
    "        sojourn_time,\n",
    "        network,\n",
    "        rider_types,\n",
    "        arrival_rates,\n",
    "        arrival_types,\n",
    "        arrival_times,\n",
    "        beta0,\n",
    "        beta1,\n",
    "        MAX_DETOUR_RATE,\n",
    "        opt_params[beta0, beta1][MATCH_KEY],\n",
    "        sim_params,\n",
    "        fluid_disutility,\n",
    "        fluid_active_disutility,\n",
    "        fluid_passive_disutility,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # save the optimal match-based weights\n",
    "    match_weights[beta0, beta1] = match_affine_weights\n",
    "    match_active_disutilities[beta0, beta1] = match_active_disutility\n",
    "    match_passive_disutilities[beta0, beta1] = match_passive_disutility\n",
    "    training_time[beta0, beta1][MATCH_KEY] = match_time\n",
    "    print(f\"Match-based pricing policy was trained in {match_time:.2f} seconds.\")\n",
    "\n",
    "    # set the warmup weights for beta0=0.05, beta1=0.675\n",
    "    if beta0 == 0 and beta1 == 0:\n",
    "        opt_params[0.05, 0.675][STATIC_KEY][\"warmup_weights\"] = static_weights[\n",
    "            beta0, beta1\n",
    "        ]\n",
    "        opt_params[0.05, 0.675][MATCH_KEY][\"warmup_weights\"] = match_weights[\n",
    "            beta0, beta1\n",
    "        ]\n",
    "\n",
    "# =================== save the training results ===================\n",
    "# create the pricing and matching policies based on the training results\n",
    "beta0, beta1 = 0.05, 0.675\n",
    "pricing_policy = dict()\n",
    "matching_policy = dict()\n",
    "\n",
    "instance_data = InstanceData(\n",
    "    c,\n",
    "    sojourn_time,\n",
    "    network,\n",
    "    rider_types,\n",
    "    arrival_rates,\n",
    "    arrival_types,\n",
    "    arrival_times,\n",
    "    beta0,\n",
    "    beta1,\n",
    "    MAX_DETOUR_RATE,\n",
    ")\n",
    "\n",
    "# create the static pricing policy\n",
    "static_instance = copy.deepcopy(instance_data)\n",
    "static_instance.disutility = static_disutilities[beta0, beta1]\n",
    "pricing_policy[STATIC_KEY] = StaticPricingPolicy(\n",
    "    static_instance, static_prices[beta0, beta1]\n",
    ")\n",
    "matching_policy[STATIC_KEY] = AffineMatchingPolicy(\n",
    "    static_instance,\n",
    "    static_weights[beta0, beta1],\n",
    "    match_flag=pricing_policy[STATIC_KEY].match_flag,\n",
    ")\n",
    "\n",
    "# create the iterative pricing policy\n",
    "iterative_instance = copy.deepcopy(instance_data)\n",
    "iterative_instance.disutility = iterative_disutilities[beta0, beta1]\n",
    "pricing_policy[ITERATIVE_KEY] = StaticPricingPolicy(\n",
    "    iterative_instance, iterative_prices[beta0, beta1]\n",
    ")\n",
    "matching_policy[ITERATIVE_KEY] = AffineMatchingPolicy(\n",
    "    iterative_instance,\n",
    "    iterative_weights[beta0, beta1],\n",
    "    match_flag=pricing_policy[ITERATIVE_KEY].match_flag,\n",
    ")\n",
    "\n",
    "# create the match-based pricing policy\n",
    "match_instance = copy.deepcopy(instance_data)\n",
    "match_instance.active_disutility = match_active_disutilities[beta0, beta1]\n",
    "match_instance.passive_disutility = match_passive_disutilities[beta0, beta1]\n",
    "pricing_policy[MATCH_KEY] = MatchBasedPricingPolicy(\n",
    "    match_instance, match_weights[beta0, beta1]\n",
    ")\n",
    "matching_policy[MATCH_KEY] = AffineMatchingPolicy(\n",
    "    match_instance,\n",
    "    match_weights[beta0, beta1],\n",
    "    match_flag=pricing_policy[MATCH_KEY].match_flag,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Policy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained policies on both the training and test datasets.\n",
    "- **Performance metrics:** include the average profit (\\\\$/min), average quoted price (\\\\$/mile $\\cdot$ rider), average quoted disutility (\\\\$/mile $\\cdot$ rider), average payment (\\\\$/mile $\\cdot$ request), average realized disutility (\\\\$/mile $\\cdot$ request), throughput (requests/min), match rate, cost efficiency, and average detour rate (over matched requests). Please refer to Section 4 of the paper for the detailed explanations of these metrics. \n",
    "- **Evaluation methods:**\n",
    "    - *Training data evaluation:* Performed on the synthetic training dataset, designed to be sufficiently long so that repetition is unnecessary.\n",
    "    - *Test data evaluation:* Conducted on the actual test dataset, with results averaged over 100 simulation runs for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data performance metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterative</th>\n",
       "      <th>static</th>\n",
       "      <th>static_UB</th>\n",
       "      <th>match</th>\n",
       "      <th>match vs iterative</th>\n",
       "      <th>match vs static</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>0.917</td>\n",
       "      <td>1.183</td>\n",
       "      <td>1.312</td>\n",
       "      <td>1.599</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_price</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_disutility</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_payment</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_realized_disutility</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput</th>\n",
       "      <td>2.465</td>\n",
       "      <td>3.509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.974</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rate</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_efficiency</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_detour_rate_over_matched</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              iterative  static  static_UB  match  \\\n",
       "profit                            0.917   1.183      1.312  1.599   \n",
       "ave_quoted_price                  0.882   0.844        NaN  0.830   \n",
       "ave_quoted_disutility             0.913   0.876        NaN  0.859   \n",
       "ave_payment                       0.860   0.817        NaN  0.787   \n",
       "ave_realized_disutility           0.890   0.852        NaN  0.822   \n",
       "throughput                        2.465   3.509        NaN  3.974   \n",
       "match_rate                        0.421   0.498        NaN  0.559   \n",
       "cost_efficiency                   0.146   0.179        NaN  0.227   \n",
       "ave_detour_rate_over_matched      0.043   0.043        NaN  0.030   \n",
       "\n",
       "                              match vs iterative  match vs static  \n",
       "profit                                     0.743            0.352  \n",
       "ave_quoted_price                          -0.059           -0.017  \n",
       "ave_quoted_disutility                     -0.059           -0.019  \n",
       "ave_payment                               -0.085           -0.036  \n",
       "ave_realized_disutility                   -0.076           -0.035  \n",
       "throughput                                 0.612            0.132  \n",
       "match_rate                                 0.327            0.123  \n",
       "cost_efficiency                            0.555            0.271  \n",
       "ave_detour_rate_over_matched              -0.290           -0.304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data performance metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterative</th>\n",
       "      <th>static</th>\n",
       "      <th>match</th>\n",
       "      <th>match vs iterative</th>\n",
       "      <th>match vs static</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>0.914</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_price</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_disutility</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_payment</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.788</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_realized_disutility</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput</th>\n",
       "      <td>2.452</td>\n",
       "      <td>3.473</td>\n",
       "      <td>3.962</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rate</th>\n",
       "      <td>0.416</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_efficiency</th>\n",
       "      <td>0.142</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_detour_rate_over_matched</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>-0.282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              iterative  static  match  match vs iterative  \\\n",
       "profit                            0.914   1.149  1.583               0.732   \n",
       "ave_quoted_price                  0.885   0.848  0.833              -0.059   \n",
       "ave_quoted_disutility             0.914   0.879  0.862              -0.056   \n",
       "ave_payment                       0.863   0.819  0.788              -0.086   \n",
       "ave_realized_disutility           0.892   0.854  0.824              -0.076   \n",
       "throughput                        2.452   3.473  3.962               0.616   \n",
       "match_rate                        0.416   0.489  0.561               0.349   \n",
       "cost_efficiency                   0.142   0.174  0.224               0.580   \n",
       "ave_detour_rate_over_matched      0.044   0.043  0.031              -0.286   \n",
       "\n",
       "                              match vs static  \n",
       "profit                                  0.378  \n",
       "ave_quoted_price                       -0.018  \n",
       "ave_quoted_disutility                  -0.019  \n",
       "ave_payment                            -0.038  \n",
       "ave_realized_disutility                -0.035  \n",
       "throughput                              0.141  \n",
       "match_rate                              0.148  \n",
       "cost_efficiency                         0.290  \n",
       "ave_detour_rate_over_matched           -0.282  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default performance metrics\n",
    "empty_metrics = {\n",
    "    \"profit\": 0,\n",
    "    \"ave_quoted_price\": 1,\n",
    "    \"ave_quoted_disutility\": 1,\n",
    "    \"ave_payment\": np.nan,\n",
    "    \"ave_realized_disutility\": np.nan,\n",
    "    \"throughput\": 0,\n",
    "    \"match_rate\": np.nan,\n",
    "    \"cost_efficiency\": np.nan,\n",
    "    \"ave_detour_rate_over_matched\": np.nan,\n",
    "}\n",
    "metrics_list = empty_metrics.keys()\n",
    "\n",
    "# evaluate the pricing policies on the training and test sets\n",
    "# create the instance data for evaluation\n",
    "eval_instance_data = InstanceData(\n",
    "    c,\n",
    "    sojourn_time,\n",
    "    network,\n",
    "    rider_types,\n",
    "    arrival_rates,\n",
    "    arrival_types,\n",
    "    arrival_times,\n",
    "    beta0,\n",
    "    beta1,\n",
    "    MAX_DETOUR_RATE,\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# ======================= training data evaluation =============================\n",
    "# =============================================================================\n",
    "training_metrics = defaultdict(defaultdict)\n",
    "\n",
    "# create the simulator for evaluation\n",
    "train_eval_simulator = Simulator(\n",
    "    copy.deepcopy(eval_instance_data), sim_params, use_real_data=False\n",
    ")\n",
    "train_eval_simulator.evaluation_time = training_synthetic_eval_time\n",
    "\n",
    "# training data evaluation\n",
    "for policy_key in [ITERATIVE_KEY, STATIC_KEY, MATCH_KEY]:\n",
    "    policy_params = opt_params[beta0, beta1][policy_key]\n",
    "\n",
    "    metrics, _ = evaluator(\n",
    "        policy_key,\n",
    "        pricing_policy[policy_key],\n",
    "        matching_policy[policy_key],\n",
    "        train_eval_simulator,\n",
    "        max_iter=EVAL_MAX_ITER,\n",
    "        set_type=TRAINING_SET_KEY,\n",
    "        verbose=False,\n",
    "        shrinkage_factor=policy_params[\"shrinkage_factor\"],\n",
    "        momentum_coef=policy_params[\"momentum\"],\n",
    "        update_disutility_flag=policy_params[\"update_disutil_eval\"],\n",
    "    )\n",
    "    for metric in metrics_list:\n",
    "        if policy_params[\"update_disutil_eval\"]:\n",
    "            training_metrics[policy_key][metric] = metrics[-1][metric]\n",
    "        else:\n",
    "            training_metrics[policy_key][metric] = metrics[metric]\n",
    "        # convert profit to per minute per mile\n",
    "        if metric == \"profit\":\n",
    "            training_metrics[policy_key][metric] *= 60 / 1609\n",
    "        # convert throughput to per minute\n",
    "        elif metric == \"throughput\":\n",
    "            training_metrics[policy_key][metric] *= 60\n",
    "\n",
    "# create a dataframe for the performance metrics on the training set\n",
    "training_metrics_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        training_metrics[ITERATIVE_KEY],\n",
    "        training_metrics[STATIC_KEY],\n",
    "        {\"profit\": fluid_profits[beta0, beta1] * 60 / 1609},\n",
    "        training_metrics[MATCH_KEY],\n",
    "    ],\n",
    ").T.rename(columns={0: ITERATIVE_KEY, 1: STATIC_KEY, 2: \"static_UB\", 3: MATCH_KEY})\n",
    "training_metrics_df[\"match vs iterative\"] = (\n",
    "    training_metrics_df[MATCH_KEY] - training_metrics_df[ITERATIVE_KEY]\n",
    ") / training_metrics_df[ITERATIVE_KEY]\n",
    "training_metrics_df[\"match vs static\"] = (\n",
    "    training_metrics_df[MATCH_KEY] - training_metrics_df[STATIC_KEY]\n",
    ") / training_metrics_df[STATIC_KEY]\n",
    "\n",
    "# =============================================================================\n",
    "# ======================= test data evaluation ================================\n",
    "# =============================================================================\n",
    "test_metrics = defaultdict(defaultdict)\n",
    "\n",
    "# create the simulator for evaluation\n",
    "test_eval_simulator = Simulator(\n",
    "    copy.deepcopy(eval_instance_data), sim_params, use_real_data=True\n",
    ")\n",
    "\n",
    "# evaluate trained policies on the test set\n",
    "for policy_key in [ITERATIVE_KEY, STATIC_KEY, MATCH_KEY]:\n",
    "    policy_params = opt_params[beta0, beta1][policy_key]\n",
    "\n",
    "    metrics, _ = evaluator(\n",
    "        policy_key,\n",
    "        pricing_policy[policy_key],\n",
    "        matching_policy[policy_key],\n",
    "        test_eval_simulator,\n",
    "        max_iter=EVAL_MAX_ITER,\n",
    "        set_type=TEST_SET_KEY,\n",
    "        verbose=False,\n",
    "        n_repeats=n_repeats,\n",
    "        shrinkage_factor=policy_params[\"shrinkage_factor\"],\n",
    "        momentum_coef=policy_params[\"momentum\"],\n",
    "        update_disutility_flag=policy_params[\"update_disutil_eval\"],\n",
    "    )\n",
    "    # average the performance metrics over the repetitions\n",
    "    for metric in metrics_list:\n",
    "        if policy_params[\"update_disutil_eval\"]:\n",
    "            test_metrics[policy_key][metric] = np.mean(\n",
    "                [metrics[-1][n][metric] for n in range(n_repeats)]\n",
    "            )\n",
    "        else:\n",
    "            test_metrics[policy_key][metric] = np.mean(\n",
    "                [metrics[n][metric] for n in range(n_repeats)]\n",
    "            )\n",
    "        # convert profit to per minute per mile\n",
    "        if metric == \"profit\":\n",
    "            test_metrics[policy_key][metric] *= 60 / 1609\n",
    "        # convert throughput to per minute\n",
    "        elif metric == \"throughput\":\n",
    "            test_metrics[policy_key][metric] *= 60\n",
    "\n",
    "# create a dataframe for the performance metrics on the test set\n",
    "test_metrics_df = pd.DataFrame.from_dict(test_metrics)\n",
    "test_metrics_df[\"match vs iterative\"] = (\n",
    "    test_metrics_df[MATCH_KEY] - test_metrics_df[ITERATIVE_KEY]\n",
    ") / test_metrics_df[ITERATIVE_KEY]\n",
    "test_metrics_df[\"match vs static\"] = (\n",
    "    test_metrics_df[MATCH_KEY] - test_metrics_df[STATIC_KEY]\n",
    ") / test_metrics_df[STATIC_KEY]\n",
    "\n",
    "print(\"Training data performance metrics:\")\n",
    "display(training_metrics_df.round(3))\n",
    "print(\"Test data performance metrics:\")\n",
    "display(test_metrics_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
