{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Experiments\n",
    "\n",
    "This notebook showcases the implementation of the three pricing policies (static pricing, iterative pricing, and match-based pricing), applied to the Chicago dataset. We train these policies and subject them to evaluation on both the training and test datasets, all within a specific parameter configuration. For a detailed description and complete results of the experiments please refer to Section 4 of the paper.\n",
    "\n",
    "## 1. Import packages, classes, functions, and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external packages\n",
    "import numpy as np\n",
    "import copy\n",
    "from gurobipy import *\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# internal classes, functions, and variables\n",
    "from lib.network import osm  # construct the network object\n",
    "from lib.instance_data import InstanceData  # instance data class\n",
    "from lib.utils import (\n",
    "    import_demand,  # helper function\n",
    "    results_saving,  # helper function\n",
    "    TRAINING_SET_KEY,  # training set keys\n",
    "    VALIDATION_SET_KEY,  # validation set keys\n",
    "    TEST_SET_KEY,  # test set keys\n",
    "    SYN_DATA_KEY,  # synthetic data key\n",
    "    REAL_DATA_KEY,  # real data key\n",
    "    MON_PEAK,  # peak time window keys\n",
    "    SAT_NONPEAK,  # off-peak time window keys\n",
    ")\n",
    "from lib.policies import (\n",
    "    StaticPricingAffineMatchingCombined,  # combined static pricing + affine matching policy\n",
    "    IterativePricingAffineMatchingCombined,  # combined iterative pricing + affine matching policy\n",
    "    MatchPricingAffineMatchingCombined,  # combined match-based pricing + affine matching policy\n",
    "    MatchBasedPricingPolicy,  # pure match-based pricing policy class\n",
    "    StaticPricingPolicy,  # pure static pricing policy class\n",
    "    GreedyMatchingPolicy,  # pure greedy matching policy class\n",
    "    AffineMatchingPolicy,  # pure affine matching policy class\n",
    ")\n",
    "from lib.simulation import (\n",
    "    Simulator,  # the simulator class\n",
    "    EVALUATION_KEY,  # key of doing evaluation on the synthetic training data\n",
    "    NO_SAMPLE_KEY,  # key of not doing sampling in the simulation\n",
    ")\n",
    "\n",
    "# pricing policy keys\n",
    "MATCH_KEY = \"match\"\n",
    "STATIC_KEY = \"static\"\n",
    "ITERATIVE_KEY = \"iterative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Chicago data\n",
    "\n",
    "We first load the preprocessed Chicago network data stored in the `network` object, and then calculate the shortest distances between nodes within the network. Following this, we load the preprocessed Chicago demand data (for Monday peak time, 7:30 a.m. to 8:30 a.m.).  In this dataset, we utilize 7 weeks as training data and reserve 1 week for testing purposes. We mainly use the four components of the demand data: `rider_types`, `arrival_rates`, `arrival_types`, `arrival_times`. Please refer to `README.md` for a detailed description of these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure on properties set() {'osmid'}\n",
      "Calculating shortest time matrix...\n",
      "... Done calculating shortest time matrix, 156.27604174613953 seconds\n"
     ]
    }
   ],
   "source": [
    "# import the Chicago network data, and calculate the shortest times between nodes\n",
    "with open('data/Chicago_network.pickle', 'rb') as f:\n",
    "    network_data = pickle.load(f)\n",
    "network = osm(network_data['G'], network_data['edge_keys'])\n",
    "network.calculate_shortest_times()\n",
    "\n",
    "# import the real rider demand data in Chicago\n",
    "time_window = MON_PEAK  # set the time window: MON_PEAK, or SAT_NONPEAK\n",
    "demand_file = \"data/Chicago_demands/{0}_train7_test1.pickle\".format(time_window)\n",
    "rider_types_complete, arrival_rates_complete, arrival_types, arrival_times = import_demand(demand_file)\n",
    "\n",
    "# Set `n_rider_types`, the number of rider types to be considered in the experiments\n",
    "# (default: `len(rider_types_complete)`, meaning all rider types are considered).\n",
    "# The value of `n_rider_types` can be adjusted between 0 and `len(rider_types_complete)` \n",
    "# for faster results by focusing on a subset of the rider types.\n",
    "n_rider_types = len(rider_types_complete)\n",
    "rider_types = rider_types_complete[:n_rider_types]\n",
    "arrival_rates = arrival_rates_complete[:n_rider_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameters setting\n",
    "\n",
    "Configure parameters for the instance, simulation, and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- instance data -----------\n",
    "# time_window is already set above\n",
    "c = 0.9  # cost from 0 to 2\n",
    "sojourn_time = 300  # average sojourn time in seconds, in {30, 60, 180, 300}\n",
    "\n",
    "# construct the instance data object\n",
    "instance_data = InstanceData(\n",
    "    c,\n",
    "    sojourn_time,\n",
    "    time_window,\n",
    "    network,\n",
    "    rider_types,\n",
    "    arrival_rates,\n",
    "    arrival_types,\n",
    "    arrival_times,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------- simulation parameters ------------\n",
    "# week numbers for training/validation/test data sets\n",
    "# (default: [1, 0, 0] for synthetic data; [7, 0, 1] for real data)\n",
    "data_sets_division = {\n",
    "    REAL_DATA_KEY: [7, 0, 1],\n",
    "    SYN_DATA_KEY: [1, 0, 0],\n",
    "}\n",
    "# get the test week number\n",
    "test_week = data_sets_division[REAL_DATA_KEY][TEST_SET_KEY - 1]\n",
    "\n",
    "# simulation time for constraint sampling\n",
    "# (default: 1e+5 seconds for c=0.7, 0.9 in synthetic training set;\n",
    "# 2e+5 seconds for c=1.1 in synthetic training set;\n",
    "# 3600 seconds for test set which is real data so it is shorter)\n",
    "time_limits = {TEST_SET_KEY: 3600}\n",
    "if c < 1:\n",
    "    time_limits[TRAINING_SET_KEY] = 100000\n",
    "else:\n",
    "    time_limits[TRAINING_SET_KEY] = 500000\n",
    "# parameter to control the observing rate for constraint sampling,\n",
    "# which is a portion rate of the summation of total arrival rate and abandoning rate (default: 0.1)\n",
    "observer_rate_portion = 0.1\n",
    "# a sufficiently long time for evaluating the synthetic training set (default: 2e+6 seconds)\n",
    "evaluation_time = 2000000\n",
    "# simulation time for greedy matching (to control the sample sizeg) (default: 2e+4 seconds)\n",
    "time_limit_greedy = 20000\n",
    "# number of repetitions for test set (default: 1 for synthetic training set; 10 for test set)\n",
    "repeat_times = {\n",
    "    TRAINING_SET_KEY: 1,\n",
    "    TEST_SET_KEY: 10,\n",
    "}\n",
    "\n",
    "# store the simulation-specific paramters in a dictionary\n",
    "sim_params = {\n",
    "    \"data_sets_division\": data_sets_division,\n",
    "    \"observer_rate_portion\": observer_rate_portion,\n",
    "    \"time_limits\": time_limits,\n",
    "    \"evaluation_time\": evaluation_time,\n",
    "    \"time_limit_greedy\": time_limit_greedy,\n",
    "    \"repeat_times\": repeat_times,\n",
    "}\n",
    "\n",
    "\n",
    "# ------------- algorithm parameters -------------\n",
    "# rounds of bootstrapping for constraint sampling (default: 5)\n",
    "bootstrapping_rounds = 5\n",
    "# the default static conversion (uniform for all rider types) for an arbitrary static pricing\n",
    "static_conversion_value = 0.5\n",
    "# termination gap for cutting plane method\n",
    "EPSILON_CUTTING_PLANE = 0.5\n",
    "# termination gap for subgradient method\n",
    "EPSILON_SUBGRADIENT = 1e-5\n",
    "\n",
    "# store the algorithm-specific paramters in a dictionary\n",
    "alg_params = {\n",
    "    \"bootstrapping_rounds\": bootstrapping_rounds,\n",
    "    \"static_conversion_value\": static_conversion_value,\n",
    "    \"EPSILON_CUTTING_PLANE\": EPSILON_CUTTING_PLANE,\n",
    "    \"EPSILON_SUBGRADIENT\": EPSILON_SUBGRADIENT,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Policy training\n",
    "\n",
    "We train three policies, wherein pricing and matching policies are trained concurrently. During this process, we generate a synthetic training set under an extended time period leveraging the arrival rates estimated from actual training data. This approach ensures that sufficiently many constraints are sampled to derive high-quality solutions.\n",
    "- *Static pricing*: We solve a fluid mathematical program to determine static prices (stored in `static_conversions[STATIC_KEY]`). Simultaneously, we optimize the matching policy (stored in `affine_weights[STATIC_KEY]`) by solving the ALP (Approximate Linear Program).  \n",
    "- *Iterative pricing*: Starting at an initial price, we optimize the affine matching policy by solving the ALP. Then we update the costs by simulation, followed by adjustments to the prices and affine weights. Repeat this cycle until convergence, resulting in the converged static prices (saved in `static_conversions[ITERATIVE_KEY]`) and matching policy (saved in `affine_weights[ITERATIVE_KEY]`).\n",
    "- *Match-based pricing*: We employ a method outlined in Section 3.2 of the paper to solve the ALP and obtain optimal affine weights, which are saved in `affine_weights[MATCH_KEY]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static pricing policy is trained. Training time: 9027.504397392273 seconds.\n",
      "Iterative pricing policy is trained. Training time: 27798.425683021545 seconds.\n",
      "Match-based pricing policy is trained. Training time: 39095.36449408531 seconds.\n"
     ]
    }
   ],
   "source": [
    "# initialize the simulator instance: use_real_data = False for synthetic data\n",
    "simulator_training = Simulator(instance_data, sim_params, use_real_data=False)\n",
    "\n",
    "# generate the synthetic training set\n",
    "simulator_training.events_generator(\n",
    "    time_limit=simulator_training.time_limits[TRAINING_SET_KEY]\n",
    ")\n",
    "\n",
    "# policy results\n",
    "# record the affine weights for each policy\n",
    "affine_weights = dict()\n",
    "# record the optimal static conversions for static/iterative policies\n",
    "static_conversions = dict()\n",
    "# record the sample sizes for each policy\n",
    "sample_sizes = dict()\n",
    "# record the training time for each policy\n",
    "training_time = dict()\n",
    "\n",
    "# --------------- Policy training ---------------\n",
    "policy = STATIC_KEY\n",
    "SPAMC = StaticPricingAffineMatchingCombined(instance_data, alg_params)\n",
    "(\n",
    "    static_conversions[policy],\n",
    "    affine_weights[policy],\n",
    "    static_profit_UB,\n",
    "    sample_sizes[policy],\n",
    "    training_time[policy],\n",
    ") = SPAMC.training_static(simulator_training)\n",
    "print(\n",
    "    \"Static pricing policy is trained. Training time: {0} seconds.\".format(\n",
    "        training_time[policy]\n",
    "    )\n",
    ")\n",
    "\n",
    "policy = ITERATIVE_KEY\n",
    "IPAMC = IterativePricingAffineMatchingCombined(instance_data, alg_params)\n",
    "(\n",
    "    static_conversions[policy],\n",
    "    affine_weights[policy],\n",
    "    sample_sizes[policy],\n",
    "    training_time[policy],\n",
    ") = IPAMC.training_iterative(simulator_training)\n",
    "print(\n",
    "    \"Iterative pricing policy is trained. Training time: {0} seconds.\".format(\n",
    "        training_time[policy]\n",
    "    )\n",
    ")\n",
    "\n",
    "policy = MATCH_KEY\n",
    "MPAMC = MatchPricingAffineMatchingCombined(instance_data, alg_params)\n",
    "(\n",
    "    affine_weights[policy],\n",
    "    sample_sizes[policy],\n",
    "    training_time[policy],\n",
    ") = MPAMC.training_match(\n",
    "    simulator_training,\n",
    "    static_profit_UB,\n",
    "    static_conversions[STATIC_KEY],\n",
    "    affine_weights[STATIC_KEY],\n",
    ")\n",
    "print(\n",
    "    \"Match-based pricing policy is trained. Training time: {0} seconds.\".format(\n",
    "        training_time[policy]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance evaluation\n",
    "\n",
    "We evaluate the performance of the trained policies on both the training set and the test set. Here we store the trained policy classes in `pricing_policies` and `matching_policies` dictionaries. (Additionally, it's worth noting that you can have the flexibility to implement custom pricing and matching policies in the framework (by creating classes that inherit from classes `PricingPolicy` or `MatchingPolicy`). Detailed information on the format and structure of these classes can be found in the  `README.md` and `/lib/policies.py`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store three policies in pricing and matching policies dictionaries\n",
    "pricing_policies = dict()\n",
    "matching_policies = dict()\n",
    "\n",
    "for policy in [STATIC_KEY, ITERATIVE_KEY, MATCH_KEY]:\n",
    "    if policy in [STATIC_KEY, ITERATIVE_KEY]:\n",
    "        pricing_policies[policy] = StaticPricingPolicy(\n",
    "            instance_data, static_conversions[policy]\n",
    "        )\n",
    "    else:\n",
    "        pricing_policies[policy] = MatchBasedPricingPolicy(\n",
    "            instance_data, affine_weights[policy]\n",
    "        )\n",
    "    matching_policies[policy] = AffineMatchingPolicy(\n",
    "        instance_data, affine_weights[policy]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our evaluation process, we consider a set of essential performance metrics: profit (\\\\$/min), average quoted price (\\\\$/mile $\\cdot$ rider), average payment (\\\\$/mile $\\cdot$ request), throughput (requests/min), match rate, and cost efficiency. Please refer to Section 4 of the paper for the detailed explanationd of these metrics. These metrics are saved in the dictionary `metrics`. To access the results, you should specify the policy key and data set type key. Additionally, we retain the comprehensive details of each rider arrival in pandas dataframes, which are stored in the `eyeball_metrics` dictionary. Here we initialize these two dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics initialization\n",
    "# metrics to be considered\n",
    "metrics_list = [\n",
    "    \"profit\",\n",
    "    \"ave_quoted_price\",\n",
    "    \"ave_payment\",\n",
    "    \"throughput\",\n",
    "    \"match_rate\",\n",
    "    \"cost_efficiency\",\n",
    "]\n",
    "# metrics for each policy under all repetitions (test set only)\n",
    "metrics_repeats = defaultdict(defaultdict)\n",
    "# average metrics for each policy\n",
    "metrics = defaultdict(defaultdict)\n",
    "# eyeball-level metrics in pandas dataframes, each row being a rider\n",
    "eyeball_metrics = defaultdict(defaultdict)\n",
    "for policy in [ITERATIVE_KEY, STATIC_KEY, MATCH_KEY]:\n",
    "    for set_type in [TRAINING_SET_KEY, VALIDATION_SET_KEY, TEST_SET_KEY]:\n",
    "        metrics_repeats[policy][set_type] = {i: list() for i in metrics_list}\n",
    "        metrics[policy][set_type] = {\n",
    "            \"profit\": 0,\n",
    "            \"ave_quoted_price\": 1,\n",
    "            \"ave_payment\": np.nan,\n",
    "            \"throughput\": np.nan,\n",
    "            \"match_rate\": np.nan,\n",
    "            \"cost_efficiency\": np.nan,\n",
    "        }\n",
    "        eyeball_metrics[policy][set_type] = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Training performance\n",
    "\n",
    "TWe subject the trained policies to evaluation using the synthetic training dataset, extending the simulation time to `evaluation_time = 2,000,000` seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance evaluation is done. Time: 951.8589758872986 seconds.\n"
     ]
    }
   ],
   "source": [
    "# set the data set type as training set\n",
    "set_type = TRAINING_SET_KEY\n",
    "\n",
    "# record the evaluation time\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize the simulator instance: use_real_data = False for synthetic data\n",
    "simulator_training_evaluate = Simulator(instance_data, sim_params, use_real_data=False)\n",
    "\n",
    "# generate the synthetic training set for evaluation which is sufficiently long\n",
    "simulator_training_evaluate.events_generator(\n",
    "    time_limit=simulator_training_evaluate.evaluation_time,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# training performance evaluation for each policy\n",
    "for policy in [STATIC_KEY, ITERATIVE_KEY, MATCH_KEY]:\n",
    "    # static and iterative pricing policies are evaluated only when the optimal static\n",
    "    # profit is positive (conversions are non-zero)\n",
    "    if (policy in [STATIC_KEY, ITERATIVE_KEY] and static_profit_UB > 0) or (\n",
    "        policy == MATCH_KEY\n",
    "    ):\n",
    "        simulator_training_evaluate.simulation(\n",
    "            pricing_policies[policy],\n",
    "            matching_policies[policy],\n",
    "            data_set_key=set_type,\n",
    "            sample_key=NO_SAMPLE_KEY,\n",
    "            seed=0,\n",
    "        )\n",
    "\n",
    "        # record system level metrics\n",
    "        for key in metrics_list:\n",
    "            if key == \"profit\":\n",
    "                metrics[policy][set_type][key] = (\n",
    "                    simulator_training_evaluate.metrics_list[-1][key] * 60 / 1609\n",
    "                )  # transfer to per min and mile  (originally in second and meter)\n",
    "            elif key == \"throughput\":\n",
    "                metrics[policy][set_type][key] = (\n",
    "                    simulator_training_evaluate.metrics_list[-1][key] * 60\n",
    "                )  # transfer to per min (originally in second)\n",
    "            else:\n",
    "                metrics[policy][set_type][\n",
    "                    key\n",
    "                ] = simulator_training_evaluate.metrics_list[-1][key]\n",
    "        # record rider level metrics in dataframes\n",
    "        eyeball_metrics[policy][set_type].append(\n",
    "            simulator_training_evaluate.eyeball_metrics_df_list[-1]\n",
    "        )\n",
    "\n",
    "end_time = time.time()\n",
    "print(\n",
    "    \"Training performance evaluation is done. Time: {0} seconds.\".format(\n",
    "        end_time - start_time\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Test performance\n",
    "\n",
    "We conduct evaluations on the actual test dataset, averaging the results over 10 simulation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance evaluation is done. Time: 18.141817808151245 seconds.\n"
     ]
    }
   ],
   "source": [
    "# set the data set type as test set\n",
    "set_type = TEST_SET_KEY\n",
    "\n",
    "# record the evaluation time\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize the SharedPricing instance: use_real_data = True for real data\n",
    "simulator_test = Simulator(instance_data, sim_params, use_real_data=True)\n",
    "\n",
    "# evaluate the performance of each policy on the test set\n",
    "for policy in [STATIC_KEY, ITERATIVE_KEY, MATCH_KEY]:\n",
    "    # static and iterative pricing policies are only evaluated when the optimal static\n",
    "    # profit is positive (conversions are non-zero)\n",
    "    if (policy in [STATIC_KEY, ITERATIVE_KEY] and static_profit_UB > 0) or (\n",
    "        policy == MATCH_KEY\n",
    "    ):\n",
    "        # repeat (10 times by default) for each policy\n",
    "        for it in range(repeat_times[set_type]):\n",
    "            # randomly generate the departure and conversions on the test set for each repetition\n",
    "            simulator_test.events_generator(\n",
    "                time_limit=simulator_test.time_limits[set_type], seed=it\n",
    "            )\n",
    "\n",
    "            # run the simulation based on the given policy\n",
    "            simulator_test.simulation(\n",
    "                pricing_policies[policy],\n",
    "                matching_policies[policy],\n",
    "                data_set_key=set_type,\n",
    "                sample_key=NO_SAMPLE_KEY,\n",
    "                seed=it,\n",
    "            )\n",
    "\n",
    "            # record system level metrics\n",
    "            for key in metrics_list:\n",
    "                if key == \"profit\":\n",
    "                    metrics_repeats[policy][set_type][key].append(\n",
    "                        simulator_test.metrics_list[-1][key] * 60 / 1609 / test_week\n",
    "                    )  # transfer to per min and mile  (originally in second and meter)\n",
    "                elif key == \"throughput\":\n",
    "                    metrics_repeats[policy][set_type][key].append(\n",
    "                        simulator_test.metrics_list[-1][key] * 60 / test_week\n",
    "                    )  # transfer to per min (originally in second)\n",
    "                else:\n",
    "                    metrics_repeats[policy][set_type][key].append(\n",
    "                        simulator_test.metrics_list[-1][key]\n",
    "                    )\n",
    "            # record rider level metrics\n",
    "            eyeball_metrics[policy][set_type].append(\n",
    "                simulator_test.eyeball_metrics_df_list[-1]\n",
    "            )\n",
    "\n",
    "        # calculate average metrics over the repetitions\n",
    "        for key in metrics_list:\n",
    "            metrics[policy][set_type][key] = np.mean(\n",
    "                metrics_repeats[policy][set_type][key]\n",
    "            )\n",
    "\n",
    "end_time = time.time()\n",
    "print(\n",
    "    \"Test performance evaluation is done. Time: {0} seconds.\".format(\n",
    "        end_time - start_time\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and print the results\n",
    "\n",
    "We store all the policies-related arguments and performance metric results in the `results` dictionary. Additionally, for a clear comparative evaluation of these policies, we present the training and test performance metrics in the pandas dataframe `metrics_df` under the parameters of $c=0.9, \\theta=1/5$, which have consistent results with the corresponding columns in Tables 2 and EC.2 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all policies and results data in a dictionary\n",
    "results = results_saving(\n",
    "    metrics,  # the final results of metrics under three policies on training/test sets\n",
    "    eyeball_metrics,  # the detail information for all rider arrivals\n",
    "    training_time,  # the running time for training\n",
    "    affine_weights,  # the optimal affine weights for all pricing policies\n",
    "    static_conversions,  # the optimal conversions for static/iterative pricing policy\n",
    "    sample_sizes,  # the sample sizes for all pricing policies\n",
    "    static_profit_UB,  # the optimal profit for static/iterative pricing policy\n",
    ")\n",
    "\n",
    "# organize the performance metrics results in dataframes\n",
    "metrics_df = dict()\n",
    "for set_type in [TRAINING_SET_KEY, TEST_SET_KEY]:\n",
    "    if set_type == TRAINING_SET_KEY:\n",
    "        metrics_df[set_type] = pd.DataFrame.from_dict(\n",
    "            [\n",
    "                metrics[ITERATIVE_KEY][TRAINING_SET_KEY],\n",
    "                metrics[STATIC_KEY][TRAINING_SET_KEY],\n",
    "                {\"profit\": static_profit_UB},\n",
    "                metrics[MATCH_KEY][TRAINING_SET_KEY],\n",
    "            ]\n",
    "        ).T.rename(\n",
    "            columns={0: ITERATIVE_KEY, 1: STATIC_KEY, 2: \"static_UB\", 3: MATCH_KEY}\n",
    "        )\n",
    "    else:\n",
    "        metrics_df[set_type] = pd.DataFrame.from_dict(\n",
    "            [\n",
    "                metrics[ITERATIVE_KEY][TEST_SET_KEY],\n",
    "                metrics[STATIC_KEY][TEST_SET_KEY],\n",
    "                metrics[MATCH_KEY][TEST_SET_KEY],\n",
    "            ]\n",
    "        ).T.rename(columns={0: ITERATIVE_KEY, 1: STATIC_KEY, 2: MATCH_KEY})\n",
    "    metrics_df[set_type][\"match vs iterative\"] = (\n",
    "        metrics_df[set_type][MATCH_KEY] - metrics_df[set_type][ITERATIVE_KEY]\n",
    "    ) / metrics_df[set_type][ITERATIVE_KEY]\n",
    "    metrics_df[set_type][\"match vs static\"] = (\n",
    "        metrics_df[set_type][MATCH_KEY] - metrics_df[set_type][STATIC_KEY]\n",
    "    ) / metrics_df[set_type][STATIC_KEY]\n",
    "    if set_type == TRAINING_SET_KEY:\n",
    "        metrics_df[set_type][\"match vs static_UB\"] = (\n",
    "            metrics_df[set_type][MATCH_KEY] - metrics_df[set_type][\"static_UB\"]\n",
    "        ) / metrics_df[set_type][\"static_UB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results when time window = MON-PEAK, c = 0.9, and sojourn time = 300 seconds:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterative</th>\n",
       "      <th>static</th>\n",
       "      <th>static_UB</th>\n",
       "      <th>match</th>\n",
       "      <th>match vs iterative</th>\n",
       "      <th>match vs static</th>\n",
       "      <th>match vs static_UB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>2.320160</td>\n",
       "      <td>2.559291</td>\n",
       "      <td>2.587818</td>\n",
       "      <td>2.984788</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.166256</td>\n",
       "      <td>0.153399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_price</th>\n",
       "      <td>0.864328</td>\n",
       "      <td>0.826483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822395</td>\n",
       "      <td>-0.048515</td>\n",
       "      <td>-0.004946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_payment</th>\n",
       "      <td>0.842847</td>\n",
       "      <td>0.806512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786973</td>\n",
       "      <td>-0.066292</td>\n",
       "      <td>-0.024226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput</th>\n",
       "      <td>3.845100</td>\n",
       "      <td>4.913160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.024970</td>\n",
       "      <td>0.306850</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rate</th>\n",
       "      <td>0.589748</td>\n",
       "      <td>0.614598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664123</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_efficiency</th>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.230143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270939</td>\n",
       "      <td>0.255748</td>\n",
       "      <td>0.177264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  iterative    static  static_UB     match   \n",
       "profit             2.320160  2.559291   2.587818  2.984788  \\\n",
       "ave_quoted_price   0.864328  0.826483        NaN  0.822395   \n",
       "ave_payment        0.842847  0.806512        NaN  0.786973   \n",
       "throughput         3.845100  4.913160        NaN  5.024970   \n",
       "match_rate         0.589748  0.614598        NaN  0.664123   \n",
       "cost_efficiency    0.215759  0.230143        NaN  0.270939   \n",
       "\n",
       "                  match vs iterative  match vs static  match vs static_UB  \n",
       "profit                      0.286458         0.166256            0.153399  \n",
       "ave_quoted_price           -0.048515        -0.004946                 NaN  \n",
       "ave_payment                -0.066292        -0.024226                 NaN  \n",
       "throughput                  0.306850         0.022757                 NaN  \n",
       "match_rate                  0.126114         0.080581                 NaN  \n",
       "cost_efficiency             0.255748         0.177264                 NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Training results when time window = {1}, c = {0}, and sojourn time = {2} seconds:\".format(\n",
    "        c, time_window, sojourn_time\n",
    "    )\n",
    ")\n",
    "metrics_df[TRAINING_SET_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results when time window = MON-PEAK, c = 0.9, and sojourn time = 300 seconds:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterative</th>\n",
       "      <th>static</th>\n",
       "      <th>match</th>\n",
       "      <th>match vs iterative</th>\n",
       "      <th>match vs static</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>2.199755</td>\n",
       "      <td>2.558417</td>\n",
       "      <td>2.996596</td>\n",
       "      <td>0.362241</td>\n",
       "      <td>0.171270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_quoted_price</th>\n",
       "      <td>0.866908</td>\n",
       "      <td>0.829754</td>\n",
       "      <td>0.825062</td>\n",
       "      <td>-0.048271</td>\n",
       "      <td>-0.005655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_payment</th>\n",
       "      <td>0.845201</td>\n",
       "      <td>0.810280</td>\n",
       "      <td>0.790574</td>\n",
       "      <td>-0.064631</td>\n",
       "      <td>-0.024320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput</th>\n",
       "      <td>3.755000</td>\n",
       "      <td>4.846667</td>\n",
       "      <td>4.953333</td>\n",
       "      <td>0.319130</td>\n",
       "      <td>0.022008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rate</th>\n",
       "      <td>0.573888</td>\n",
       "      <td>0.613074</td>\n",
       "      <td>0.661052</td>\n",
       "      <td>0.151882</td>\n",
       "      <td>0.078258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_efficiency</th>\n",
       "      <td>0.205017</td>\n",
       "      <td>0.224696</td>\n",
       "      <td>0.264982</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.179293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  iterative    static     match  match vs iterative   \n",
       "profit             2.199755  2.558417  2.996596            0.362241  \\\n",
       "ave_quoted_price   0.866908  0.829754  0.825062           -0.048271   \n",
       "ave_payment        0.845201  0.810280  0.790574           -0.064631   \n",
       "throughput         3.755000  4.846667  4.953333            0.319130   \n",
       "match_rate         0.573888  0.613074  0.661052            0.151882   \n",
       "cost_efficiency    0.205017  0.224696  0.264982            0.292491   \n",
       "\n",
       "                  match vs static  \n",
       "profit                   0.171270  \n",
       "ave_quoted_price        -0.005655  \n",
       "ave_payment             -0.024320  \n",
       "throughput               0.022008  \n",
       "match_rate               0.078258  \n",
       "cost_efficiency          0.179293  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Test results when time window = {1}, c = {0}, and sojourn time = {2} seconds:\".format(\n",
    "        c, time_window, sojourn_time\n",
    "    )\n",
    ")\n",
    "metrics_df[TEST_SET_KEY]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
